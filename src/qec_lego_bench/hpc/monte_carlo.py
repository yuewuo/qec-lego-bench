from typing import (
    Any,
    Protocol,
    Callable,
    TypeVar,
    Type,
    Iterator,
    Optional,
    Tuple,
    Concatenate,
    cast,
)
from dataclasses import dataclass
from dataclasses_json import dataclass_json
from distributed import Future, Client, wait
from concurrent.futures._base import DoneAndNotDoneFutures, FIRST_COMPLETED
from concurrent.futures import Future as ConcurrentFuture
import functools
import time
import sys
import math
import sinter
from qec_lego_bench.stats import Stats


class MonteCarloResult(Protocol):
    def __add__(self: "Result", other: "Result") -> "Result": ...

    # the following two methods are automatically generated by the dataclass_json decorator
    def to_dict(self) -> dict: ...
    @classmethod
    def from_dict(cls: Type["Result"], value: dict) -> "Result": ...


Result = TypeVar("Result", bound=MonteCarloResult)


@dataclass_json
@dataclass
class LogicalErrorResult(MonteCarloResult):
    errors: int = 0
    discards: int = 0

    def __add__(self, other: "LogicalErrorResult") -> "LogicalErrorResult":
        return LogicalErrorResult(self.errors + other.errors, self.discards + other.discards)  # type: ignore

    def stats_of(self, job: "MonteCarloJob") -> Stats:
        return Stats(
            sinter.AnonTaskStats(
                shots=job.shots,
                errors=self.errors,
                discards=self.discards,
                seconds=job.duration,
            )
        )


"""
A function to run the Monte Carlo result, given the number of shots and other parameters provided by the user
"""
MonteCarloFunc = Callable[Concatenate[int, ...], MonteCarloResult]

"""
A function to decide which is the next job to run and how many shots to run
"""
MonteCarloNextJob = Callable[
    ["MonteCarloJobExecutor"], Optional[Tuple["MonteCarloJob", int]]
]


@dataclass(frozen=True)
class JobParameters:
    args: tuple
    kwargs: dict

    def __post_init__(self):
        assert hash(self) != 0, "test hash value to make sure it is hashable"

    @functools.cached_property
    def hash(self) -> int:
        _kwargs_ordered = tuple((k, self.kwargs[k]) for k in sorted(self.kwargs.keys()))
        for arg in self.args:
            try:
                hash(arg)
            except Exception as e:
                print(f"Error hashing positional argument {arg}: {e}")
                raise e
        for key, value in _kwargs_ordered:
            assert key != "shots", "`shots` is a reserved keyword argument"
            try:
                hash(key)
                hash(value)
            except Exception as e:
                print(f"Error hashing keyword argument {key}={value}: {e}")
                raise e
        return hash((self.args, _kwargs_ordered))

    def __hash__(self):
        return self.hash


class MonteCarloJob:

    def __init__(self, *args, **kwargs) -> None:
        self._params = JobParameters(args, kwargs)
        self.finished_shots: int = 0
        self.pending_shots: int = 0
        self.duration: float = 0  # overall time of the finished shots
        self.result: Optional[MonteCarloResult] = None

    @property
    def args(self) -> tuple:
        return self._params.args

    @property
    def kwargs(self) -> dict:
        return self._params.kwargs

    def __getitem__(self, key: str) -> Any:
        return self.kwargs[key]

    @property
    def expecting_shots(self) -> int:
        return self.pending_shots + self.finished_shots

    @property
    def shots(self) -> int:
        return self.finished_shots

    def __hash__(self):
        return hash(self._params)


@dataclass
class MonteCarloExecutorConfig:
    # at least run 10 shots before sufficient estimation time is reached
    min_shots_before_estimation: int = 10
    # run at least 10s for single thread before it can spawn multiple
    min_multi_thread_duration: float = 10
    # let each job run for about 3 minutes to reduce scheduling overhead
    target_job_time: float = 180

    # return the split of the shots and how many threads
    def warmed_up_split(self, job: MonteCarloJob, shots: int) -> Tuple[int, int]:
        if job.finished_shots < self.min_shots_before_estimation:
            return self.min_shots_before_estimation, 1
        per_shot_time = job.duration / job.finished_shots
        if job.duration < self.min_multi_thread_duration:
            target_shots = int(self.min_multi_thread_duration / per_shot_time)
            target_shots = min(shots, target_shots)
            return target_shots, 1
        # we have gathered sufficient data to estimate the runtime
        if shots * per_shot_time < self.target_job_time:
            return shots, 1
        threads = math.ceil(shots * per_shot_time / self.target_job_time)
        shots_per_thread = math.ceil(shots / threads)
        return shots_per_thread, threads


@dataclass
class MonitoredResult:
    result: MonteCarloResult
    shots: int = 0
    duration: float = 0


def monitored_job(
    func: MonteCarloFunc, shots: int, args: tuple, kwargs: dict
) -> MonitoredResult:
    start = time.time()
    result = func(shots, *args, **kwargs)
    duration = time.time() - start
    return MonitoredResult(result, shots, duration)


class MonteCarloJobExecutor:
    jobs: dict[int, MonteCarloJob]

    def __init__(
        self,
        client: Client,
        func: MonteCarloFunc,
        jobs,
        config: Optional[MonteCarloExecutorConfig] = None,
        filename: Optional[str] = None,
    ) -> None:
        assert isinstance(client, Client)
        assert callable(func)
        self.client = client
        self.func = func
        self.jobs: dict[int, MonteCarloJob] = {hash(job): job for job in jobs}
        self.pending_futures: list[Future] = []
        self.future_info: dict[Future, MonteCarloJob] = {}
        self.config = config or MonteCarloExecutorConfig()

    def __iter__(self) -> Iterator[MonteCarloJob]:
        for job in self.jobs.values():
            yield job

    def add_job(self, job: MonteCarloJob) -> None:
        assert hash(job) not in self.jobs, "Job already exists"
        self.jobs[hash(job)] = job

    def get_job(self, *args, **kwargs) -> Optional[MonteCarloJob]:
        hash_value = hash(JobParameters(args, kwargs))
        if hash_value not in self.jobs:
            return None
        return self.jobs[hash_value]

    def execute(
        self,
        next_job: MonteCarloNextJob,
        timeout: float = sys.float_info.max,
        loop_callback: Optional[Callable[["MonteCarloJobExecutor"], None]] = None,
    ) -> None:
        if loop_callback is not None:
            loop_callback(self)
        start = time.time()
        # the remaining shots due to insufficient number of samples for estimation runtime
        pending_submit: dict[MonteCarloJob, tuple[int, Future]] = {}
        try:
            while True:
                remaining_time = timeout - (time.time() - start)
                if remaining_time <= 0:
                    break
                futures: DoneAndNotDoneFutures = wait(
                    self.pending_futures,
                    return_when=FIRST_COMPLETED,
                    timeout=timeout - (time.time() - start),
                )
                for done in futures.done:
                    assert isinstance(done, Future)
                    job = self.future_info[done]
                    job_result: MonitoredResult = done.result()
                    if job.result is None:
                        job.result = job_result.result
                    else:
                        job.result += job_result.result
                    job.duration += job_result.duration
                    job.finished_shots += job_result.shots
                    job.pending_shots -= job_result.shots
                    del self.future_info[done]
                self.pending_futures = list(futures.not_done)  # type: ignore
                # get the next job to run
                next = next_job(self)
                while next is not None:
                    job, shots = next
                    # submit jobs such that it runs for this number of shots
                    job.pending_shots += shots
                    if job in pending_submit:
                        remaining, blocking_future = pending_submit[job]
                        pending_submit[job] = remaining + shots, blocking_future
                    else:
                        # add the job to the pending submit and mock a done job such that it will be submitted later
                        mock_future: ConcurrentFuture = ConcurrentFuture()
                        mock_future.set_result(0)
                        pending_submit[job] = shots, cast(Future, mock_future)
                    next = next_job(self)
                for job in list(pending_submit.keys()):
                    shots, done_future = pending_submit[job]
                    del pending_submit[job]
                    if not done_future.done():
                        continue  # keep waiting
                    shots_per_thread, threads = self.config.warmed_up_split(job, shots)
                    for _ in range(threads):
                        future = self.client.submit(
                            monitored_job,
                            self.func,
                            shots_per_thread,
                            job.args,
                            job.kwargs,
                        )
                        self.pending_futures.append(future)
                        self.future_info[future] = job
                    actual_shots = shots_per_thread * threads
                    if actual_shots < shots:
                        pending_submit[job] = shots - actual_shots, future
                    else:
                        # adjust actual pending shots
                        job.pending_shots += actual_shots - shots
                # call user callback such that they can do some plotting of the intermediate results
                if loop_callback is not None:
                    loop_callback(self)
                if len(self.pending_futures) == 0:
                    break
        finally:
            # cancel all pending futures
            for future in self.pending_futures:
                future.cancel()
            self.pending_futures = []
            for job in self:
                job.pending_shots = 0
