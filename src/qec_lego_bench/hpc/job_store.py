from dataclasses import dataclass
from dataclasses_json import dataclass_json
import functools
from stablehash import stablehash
from typing import Sequence, Optional, Iterator, Any, Protocol, TypeVar, Type, Callable
import os
import portalocker
import json
import time
import sys


@dataclass_json
@dataclass(frozen=True)
class JobParameters:
    args: tuple
    kwargs: dict

    def __post_init__(self):
        assert self.hash != "", "test hash value to make sure it is hashable"

    @functools.cached_property
    def hash(self) -> str:
        _kwargs_ordered = tuple((k, self.kwargs[k]) for k in sorted(self.kwargs.keys()))
        for arg in self.args:
            try:
                stablehash(arg)
            except Exception as e:
                print(f"Error hashing positional argument {arg}: {e}")
                raise e
        for key, value in _kwargs_ordered:
            assert key != "shots", "`shots` is a reserved keyword argument"
            try:
                stablehash(key)
                stablehash(value)
            except Exception as e:
                print(f"Error hashing keyword argument {key}={value}: {e}")
                raise e
        return stablehash((self.args, _kwargs_ordered)).hexdigest()


class JobResult(Protocol):
    # the following two methods are automatically generated by the dataclass_json decorator
    def to_dict(self) -> dict: ...
    @classmethod
    def from_dict(cls: Type["Result"], value: dict) -> "Result": ...


Result = TypeVar("Result", bound=JobResult)


class Job:
    def __init__(self, *args, **kwargs) -> None:
        self._params = JobParameters(args=args, kwargs=kwargs)
        self.result: Optional[Any] = None

    def __repr__(self):
        args = [str(arg) for arg in self.args]
        for key in self.kwargs.keys():
            args.append(f"{key}={self.kwargs[key]}")
        return f"Job({', '.join(args)})"

    @property
    def args(self) -> tuple:
        return self._params.args

    @property
    def kwargs(self) -> dict:
        return self._params.kwargs

    @property
    def hash(self) -> str:
        return self._params.hash

    @property
    def parameters(self) -> JobParameters:
        return self._params


JobFunc = Callable[..., JobResult]


class JobStore:
    def __init__(
        self,
        func: JobFunc,
        jobs: Sequence[Job],
        *,
        # used when reading from file
        result_type: Type[JobResult],
        filename: Optional[str] = None,
    ) -> None:
        assert callable(func)
        self.func = func
        for job in jobs:
            assert isinstance(job, Job)
        self.jobs: dict[str, Job] = {job.hash: job for job in jobs}
        if len(self.jobs) != jobs:
            # report which jobs have conflicting hash
            job_map = {}
            for job in jobs:
                if job.hash not in job_map:
                    job_map[job.hash] = job
                else:
                    raise ValueError(
                        f"Job hash conflict: {job_map[job.hash]} and {job} have the same hash"
                    )
        self.result_type = result_type
        self.filename = filename
        if filename is not None:
            self.load_from_file(filename)  # load from file on initialization

    def __iter__(self) -> Iterator[Job]:
        for job in self.jobs.values():
            yield job

    def add_job(
        self, job: Job, load_from_file: bool = True, skip_if_exists: bool = False
    ) -> None:
        if skip_if_exists and job.hash in self.jobs:
            return
        assert job.hash not in self.jobs, "Job already exists"
        self.jobs[job.hash] = job
        if load_from_file and self.filename is not None:
            self.load_from_file(self.filename, job)

    def get_job(self, *args, **kwargs) -> Optional[Job]:
        hash_value = JobParameters(args, kwargs).hash
        if hash_value not in self.jobs:
            return None
        return self.jobs[hash_value]

    def get_job_assert(self, *args, **kwargs) -> Job:
        job = self.get_job(*args, **kwargs)
        assert job is not None, f"Job not found: {args}, {kwargs}"
        return job

    def load_from_file(self, filename: str, target_job: Optional[Job] = None) -> None:
        if not os.path.exists(filename):
            return
        with portalocker.Lock(filename, "r") as f:
            persist = json.load(f)
            jobs = self.jobs.values() if target_job is None else [target_job]
            for job in jobs:
                if job.hash not in persist:
                    continue
                entry = persist[job.hash]
                # sanity check
                for entry_arg, arg in zip(entry["args"], job.args):
                    assert entry_arg == str(arg), "Hash conflict"
                assert entry["kwargs"].keys() == job.kwargs.keys(), "Hash conflict"
                for key in job.kwargs.keys():
                    assert entry["kwargs"][key] == str(job.kwargs[key]), "Hash conflict"
                # add to current value
                if "result" in entry and entry["result"] is not None:
                    job.result = self.result_type.from_dict(entry["result"])

    def update_file(self, filename: str) -> None:
        with portalocker.Lock(
            filename, "r+" if os.path.exists(filename) else "w+"
        ) as f:
            content = f.read()
            if content == "":
                persist = {}
            else:
                persist = json.loads(content)
            f.seek(0)
            for job in self.jobs.values():
                if job.hash not in persist:
                    persist[job.hash] = {
                        "args": [str(arg) for arg in job.args],
                        "kwargs": {
                            key: str(value) for key, value in job.kwargs.items()
                        },
                    }
                    entry = persist[job.hash]
                else:
                    entry = persist[job.hash]
                    # sanity check
                    for entry_arg, arg in zip(entry["args"], job.args):
                        assert entry_arg == str(arg), "Hash conflict"
                    assert entry["kwargs"].keys() == job.kwargs.keys(), "Hash conflict"
                    for key in job.kwargs.keys():
                        assert entry["kwargs"][key] == str(
                            job.kwargs[key]
                        ), "Hash conflict"
                # update value only if I have more information than the storage file
                if job.result is not None:
                    entry["result"] = job.result.to_dict()
            json.dump(persist, f, indent=2)
            f.truncate()

    def execute(
        self,
        timeout: float = sys.float_info.max,
        loop_callback: Optional[Callable[["JobStore"], None]] = None,
        starting_index_bias: float = 0.0,
        reload_from_file_every: float = 10.0,  # reload from file every 10s
    ) -> None:
        if loop_callback is not None:
            loop_callback(self)
        start = time.time()
        exceptions = []

        def get_pending_jobs() -> list[Job]:
            pending_jobs = [job for job in self.jobs.values() if job.result is None]
            starting_index = int(
                max(0.0, min(1.0, starting_index_bias)) * len(pending_jobs)
            )
            return pending_jobs[starting_index:] + pending_jobs[:starting_index]

        pending_jobs = get_pending_jobs()
        last_reload_from_file = time.time()
        while len(pending_jobs) > 0:
            remaining_time = timeout - (time.time() - start)
            if remaining_time <= 0:
                raise TimeoutError()
            job = pending_jobs.pop(0)
            try:
                result = self.func(*job.args, **job.kwargs)
                job.result = result
                # save to file
                if self.filename is not None:
                    self.update_file(self.filename)
                # call user callback such that they can do some plotting of the intermediate results
                if loop_callback is not None:
                    loop_callback(self)
            except Exception as e:
                print(f"job {job} execution error", e)
                exceptions.append(e)
            if time.time() - last_reload_from_file >= reload_from_file_every:
                if self.filename is not None:
                    self.load_from_file(
                        self.filename
                    )  # load from file on initialization
                last_reload_from_file = time.time()
            pending_jobs = get_pending_jobs()
        if len(exceptions) > 0:
            raise exceptions[0]
