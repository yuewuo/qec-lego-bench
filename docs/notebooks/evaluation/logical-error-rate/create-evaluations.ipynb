{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dac5cbe-2f50-4d12-834a-a0f5c3fca75d",
   "metadata": {},
   "source": [
    "# Create Notebooks but not run them\n",
    "\n",
    "One should check [how-to-run-notebook-on-cluster.ipynb](../how-to-run-notebook-on-cluster.ipynb) for executing the notebooks on a cluster.\n",
    "For here, we only generate evaluation notebooks **if they do not exist**.\n",
    "Thus, you can effectively force a rerun, or update the notebook to the latest version, by removing the old notebooks.\n",
    "You can also choose to remove the JSON data or not, depending on your needs.\n",
    "\n",
    "## Tips\n",
    "\n",
    "When you first run some notebook from scratch, try to use a small number of workers (e.g., `slurm_maximum_jobs=30`).\n",
    "This is because normally at the beginning of the evaluation, the jobs are highly sequential.\n",
    "At this stage, the submitter and the executor are still trying to figure out how fast each shot runs and how many shots we need to gather.\n",
    "They don't want to submit too much jobs that it takes forever to execute.\n",
    "After it gathers enough data, e.g., has gone to the next (higher precision) submitter, then you can increase the number of workers because those jobs are highly parallelizable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c795c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb35a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available keys\n",
      "    - decoder_eval: str = '\"mwpm\"'\n",
      "    - code_eval: str = 'f\"rsc(d@{c.d},p@{p})\"'\n",
      "    - noise_eval: str = '\"none\"'\n",
      "    - config_vec_eval: str = '[dmap(d@3), dmap(d@5), dmap(d@7), dmap(d@9), dmap(d@11)]'\n",
      "    - p_center: float = 0.01\n",
      "    - per10_p_count: int = 3\n",
      "    - p_bias: int = 0\n",
      "    - slurm_maximum_jobs: None = 30\n",
      "    - slurm_cores_per_node: int = 10\n",
      "    - slurm_mem_per_job: int = 2\n",
      "    - slurm_walltime: str = \"1-00:00:00\"\n",
      "    - local_maximum_jobs: None = 10\n",
      "    - force_finished: bool = False\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import papermill as pm\n",
    "from dotmap import DotMap as dmap\n",
    "from slugify import slugify\n",
    "from qec_lego_bench.hpc.cluster_util import tmux_list_script\n",
    "import nbstripout  # please install, and we will call it from command line\n",
    "import subprocess\n",
    "\n",
    "template_path = 'template.ipynb'\n",
    "\n",
    "inspected = pm.inspect_notebook(template_path)\n",
    "print(\"available keys\")\n",
    "for key, value in inspected.items():\n",
    "    v = dmap(value)\n",
    "    print(f\"    - {key}: {v.inferred_type_name} = {v.default}\")\n",
    "\n",
    "# remove all the output from the notebook\n",
    "def remove_notebook_output(nb_path: str):\n",
    "    subprocess.Popen(f\"nbstripout {nb_path}\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cda08c",
   "metadata": {},
   "source": [
    "## Rotated Surface Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbd6b87f-d9bf-4d02-a6a7-504559262b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_vec_eval: [dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpm\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpf\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"huf\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': 'f\"mwpf(c@{50*c.d})\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5)\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf\"'}\n",
      "parameters: {'code_eval': 'f\"rsc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf(max_iter@5)\"'}\n"
     ]
    }
   ],
   "source": [
    "d_vec = [3, 5, 7, 9, 11]\n",
    "\n",
    "code_parameters = dict(\n",
    "    code_eval = 'f\"rsc(d@{c.d},p@{p})\"',\n",
    "    noise_eval = '\"none\"',\n",
    "    p_center = 0.01,\n",
    "    per10_p_count = 3,\n",
    "    p_bias = -2,  # 0.0022\n",
    "    slurm_mem_per_job = 4,\n",
    "    config_vec_eval=\"[\" + \",\".join(f\"dmap(d@{d})\" for d in d_vec) + \"]\",\n",
    "    slurm_maximum_jobs=30,  # smaller instances for kick starts\n",
    ")\n",
    "\n",
    "print(\"config_vec_eval:\", code_parameters[\"config_vec_eval\"])\n",
    "\n",
    "folder = slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "decoder_eval_vec = [\n",
    "    '\"mwpm\"',\n",
    "    '\"mwpf\"',\n",
    "    '\"huf\"',\n",
    "    'f\"mwpf(c@{50*c.d})\"',  # auto scaling\n",
    "    '\"bposd\"',\n",
    "    '\"bposd(max_iter@5)\"',\n",
    "    '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"',\n",
    "    '\"bpuf\"',\n",
    "    '\"bpuf(max_iter@5)\"',\n",
    "]\n",
    "\n",
    "jobs: list[tuple[str, str]] = []\n",
    "for decoder_eval in decoder_eval_vec:\n",
    "    parameters = dict(\n",
    "        **code_parameters,\n",
    "        decoder_eval=decoder_eval,\n",
    "    )\n",
    "    notebook_filename = slugify(decoder_eval) + \".ipynb\"\n",
    "    notebook_path = os.path.join(folder, notebook_filename)\n",
    "    if os.path.exists(notebook_path):\n",
    "        print(\"skip existing:\", notebook_path)\n",
    "    else:\n",
    "        print(\"parameters:\", parameters)\n",
    "        pm.execute_notebook(\n",
    "            template_path,\n",
    "            notebook_path,\n",
    "            parameters=parameters,\n",
    "            prepare_only=True,  # do not run the notebook\n",
    "        )\n",
    "        remove_notebook_output(notebook_path)\n",
    "    # create tmux session to run these commands\n",
    "    tmux_name = slugify(decoder_eval) + \"_\" + slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "    command = f\"srun --time=23:55:00 --mem=10G --cpus-per-task=2 papermill {notebook_filename} ${{RID}}.{notebook_filename}\"\n",
    "    jobs.append((tmux_name, command))\n",
    "\n",
    "script_path = os.path.join(folder, \"run_all.sh\")\n",
    "script = tmux_list_script(jobs, prefix=\"RID=zz-3\")\n",
    "if os.path.exists(script_path):\n",
    "    print(\"skip existing:\", script_path)\n",
    "else:\n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c8430",
   "metadata": {},
   "source": [
    "## Un-rotated Surface Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f164fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_vec_eval: [dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpm\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpf\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"huf\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': 'f\"mwpf(c@{50*c.d})\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5)\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf\"'}\n",
      "parameters: {'code_eval': 'f\"usc(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -1, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf(max_iter@5)\"'}\n"
     ]
    }
   ],
   "source": [
    "d_vec = [3, 5, 7, 9, 11]\n",
    "\n",
    "code_parameters = dict(\n",
    "    code_eval = 'f\"usc(d@{c.d},p@{p})\"',\n",
    "    noise_eval = '\"none\"',\n",
    "    p_center = 0.01,\n",
    "    per10_p_count = 3,\n",
    "    p_bias = -1,  # 0.0046\n",
    "    slurm_mem_per_job = 4,\n",
    "    config_vec_eval=\"[\" + \",\".join(f\"dmap(d@{d})\" for d in d_vec) + \"]\",\n",
    "    slurm_maximum_jobs=30,  # smaller instances for kick starts\n",
    ")\n",
    "\n",
    "print(\"config_vec_eval:\", code_parameters[\"config_vec_eval\"])\n",
    "\n",
    "folder = slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "decoder_eval_vec = [\n",
    "    '\"mwpm\"',\n",
    "    '\"mwpf\"',\n",
    "    '\"huf\"',\n",
    "    'f\"mwpf(c@{50*c.d})\"',  # auto scaling\n",
    "    '\"bposd\"',\n",
    "    '\"bposd(max_iter@5)\"',\n",
    "    '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"',\n",
    "    '\"bpuf\"',\n",
    "    '\"bpuf(max_iter@5)\"',\n",
    "]\n",
    "\n",
    "jobs: list[tuple[str, str]] = []\n",
    "for decoder_eval in decoder_eval_vec:\n",
    "    parameters = dict(\n",
    "        **code_parameters,\n",
    "        decoder_eval=decoder_eval,\n",
    "    )\n",
    "    notebook_filename = slugify(decoder_eval) + \".ipynb\"\n",
    "    notebook_path = os.path.join(folder, notebook_filename)\n",
    "    if os.path.exists(notebook_path):\n",
    "        print(\"skip existing:\", notebook_path)\n",
    "    else:\n",
    "        print(\"parameters:\", parameters)\n",
    "        pm.execute_notebook(\n",
    "            template_path,\n",
    "            notebook_path,\n",
    "            parameters=parameters,\n",
    "            prepare_only=True,  # do not run the notebook\n",
    "        )\n",
    "        remove_notebook_output(notebook_path)\n",
    "    # create tmux session to run these commands\n",
    "    tmux_name = slugify(decoder_eval) + \"_\" + slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "    command = f\"srun --time=23:55:00 --mem=10G --cpus-per-task=2 papermill {notebook_filename} ${{RID}}.{notebook_filename}\"\n",
    "    jobs.append((tmux_name, command))\n",
    "\n",
    "script_path = os.path.join(folder, \"run_all.sh\")\n",
    "script = tmux_list_script(jobs, prefix=\"RID=zz-3\")\n",
    "if os.path.exists(script_path):\n",
    "    print(\"skip existing:\", script_path)\n",
    "else:\n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b15804",
   "metadata": {},
   "source": [
    "## Repetition Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ba00612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_vec_eval: [dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpm\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpf\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"huf\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': 'f\"mwpf(c@{50*c.d})\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5)\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf\"'}\n",
      "parameters: {'code_eval': 'f\"rep(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.1, 'per10_p_count': 3, 'p_bias': -2, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11),dmap(d@13),dmap(d@15)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf(max_iter@5)\"'}\n"
     ]
    }
   ],
   "source": [
    "d_vec = [3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "code_parameters = dict(\n",
    "    code_eval = 'f\"rep(d@{c.d},p@{p})\"',\n",
    "    noise_eval = '\"none\"',\n",
    "    p_center = 0.1,\n",
    "    per10_p_count = 3,\n",
    "    p_bias = -2,  # 0.022\n",
    "    slurm_mem_per_job = 4,\n",
    "    config_vec_eval=\"[\" + \",\".join(f\"dmap(d@{d})\" for d in d_vec) + \"]\",\n",
    "    slurm_maximum_jobs=30,  # smaller instances for kick starts\n",
    ")\n",
    "\n",
    "print(\"config_vec_eval:\", code_parameters[\"config_vec_eval\"])\n",
    "\n",
    "folder = slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "decoder_eval_vec = [\n",
    "    '\"mwpm\"',\n",
    "    '\"mwpf\"',\n",
    "    '\"huf\"',\n",
    "    'f\"mwpf(c@{50*c.d})\"',  # auto scaling\n",
    "    '\"bposd\"',\n",
    "    '\"bposd(max_iter@5)\"',\n",
    "    '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"',\n",
    "    '\"bpuf\"',\n",
    "    '\"bpuf(max_iter@5)\"',\n",
    "]\n",
    "\n",
    "jobs: list[tuple[str, str]] = []\n",
    "for decoder_eval in decoder_eval_vec:\n",
    "    parameters = dict(\n",
    "        **code_parameters,\n",
    "        decoder_eval=decoder_eval,\n",
    "    )\n",
    "    notebook_filename = slugify(decoder_eval) + \".ipynb\"\n",
    "    notebook_path = os.path.join(folder, notebook_filename)\n",
    "    if os.path.exists(notebook_path):\n",
    "        print(\"skip existing:\", notebook_path)\n",
    "    else:\n",
    "        print(\"parameters:\", parameters)\n",
    "        pm.execute_notebook(\n",
    "            template_path,\n",
    "            notebook_path,\n",
    "            parameters=parameters,\n",
    "            prepare_only=True,  # do not run the notebook\n",
    "        )\n",
    "        remove_notebook_output(notebook_path)\n",
    "    # create tmux session to run these commands\n",
    "    tmux_name = slugify(decoder_eval) + \"_\" + slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "    command = f\"srun --time=23:55:00 --mem=10G --cpus-per-task=2 papermill {notebook_filename} ${{RID}}.{notebook_filename}\"\n",
    "    jobs.append((tmux_name, command))\n",
    "\n",
    "script_path = os.path.join(folder, \"run_all.sh\")\n",
    "script = tmux_list_script(jobs, prefix=\"RID=zz-3\")\n",
    "if os.path.exists(script_path):\n",
    "    print(\"skip existing:\", script_path)\n",
    "else:\n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f77e26",
   "metadata": {},
   "source": [
    "## Color Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "488a1183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_vec_eval: [dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"mwpf\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"huf\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': 'f\"mwpf(c@{50*c.d})\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5)\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf\"'}\n",
      "parameters: {'code_eval': 'f\"color(d@{c.d},p@{p})\"', 'noise_eval': '\"none\"', 'p_center': 0.01, 'per10_p_count': 3, 'p_bias': -3, 'slurm_mem_per_job': 4, 'config_vec_eval': '[dmap(d@3),dmap(d@5),dmap(d@7),dmap(d@9),dmap(d@11)]', 'slurm_maximum_jobs': 30, 'decoder_eval': '\"bpuf(max_iter@5)\"'}\n"
     ]
    }
   ],
   "source": [
    "d_vec = [3, 5, 7, 9, 11]\n",
    "\n",
    "code_parameters = dict(\n",
    "    code_eval = 'f\"color(d@{c.d},p@{p})\"',\n",
    "    noise_eval = '\"none\"',\n",
    "    p_center = 0.01,\n",
    "    per10_p_count = 3,\n",
    "    p_bias = -3,  # 0.001\n",
    "    slurm_mem_per_job = 4,\n",
    "    config_vec_eval=\"[\" + \",\".join(f\"dmap(d@{d})\" for d in d_vec) + \"]\",\n",
    "    slurm_maximum_jobs=30,  # smaller instances for kick starts\n",
    ")\n",
    "\n",
    "print(\"config_vec_eval:\", code_parameters[\"config_vec_eval\"])\n",
    "\n",
    "folder = slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "decoder_eval_vec = [\n",
    "    '\"mwpf\"',\n",
    "    '\"huf\"',\n",
    "    'f\"mwpf(c@{50*c.d})\"',  # auto scaling\n",
    "    '\"bposd\"',\n",
    "    '\"bposd(max_iter@5)\"',\n",
    "    '\"bposd(max_iter@5,osd_order@10,osd_method@osd_e)\"',\n",
    "    '\"bpuf\"',\n",
    "    '\"bpuf(max_iter@5)\"',\n",
    "]\n",
    "\n",
    "jobs: list[tuple[str, str]] = []\n",
    "for decoder_eval in decoder_eval_vec:\n",
    "    parameters = dict(\n",
    "        **code_parameters,\n",
    "        decoder_eval=decoder_eval,\n",
    "    )\n",
    "    notebook_filename = slugify(decoder_eval) + \".ipynb\"\n",
    "    notebook_path = os.path.join(folder, notebook_filename)\n",
    "    if os.path.exists(notebook_path):\n",
    "        print(\"skip existing:\", notebook_path)\n",
    "    else:\n",
    "        print(\"parameters:\", parameters)\n",
    "        pm.execute_notebook(\n",
    "            template_path,\n",
    "            notebook_path,\n",
    "            parameters=parameters,\n",
    "            prepare_only=True,  # do not run the notebook\n",
    "        )\n",
    "        remove_notebook_output(notebook_path)\n",
    "    # create tmux session to run these commands\n",
    "    tmux_name = slugify(decoder_eval) + \"_\" + slugify(code_parameters[\"code_eval\"]) + \"_\" + slugify(code_parameters[\"noise_eval\"])\n",
    "    command = f\"srun --time=23:55:00 --mem=10G --cpus-per-task=2 papermill {notebook_filename} ${{RID}}.{notebook_filename}\"\n",
    "    jobs.append((tmux_name, command))\n",
    "\n",
    "script_path = os.path.join(folder, \"run_all.sh\")\n",
    "script = tmux_list_script(jobs, prefix=\"RID=zz-3\")\n",
    "if os.path.exists(script_path):\n",
    "    print(\"skip existing:\", script_path)\n",
    "else:\n",
    "    with open(script_path, \"w\") as f:\n",
    "        f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe2ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
