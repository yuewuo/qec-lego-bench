{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a27491-4a85-4ace-9632-825c2101ce1c",
   "metadata": {},
   "source": [
    "# Consistency of MWPM on RSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1b458-0da2-4bd0-87bf-40d8dfd1682b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged `parameters` and will be override by `papermill`\n",
    "json_filename: str = \"rsc-consistency-mwpf.json\"  # where to save the result, must be provided\n",
    "code: str = \"rsc(d=5,p=0.001)\"\n",
    "noise: str = \"none\"\n",
    "decoder: str = \"mwpf\"\n",
    "\n",
    "slurm_maximum_jobs: int = 100\n",
    "slurm_cores_per_node: int = 10  # (slurm_maximum_jobs // slurm_cores_per_node) should not exceed 200\n",
    "slurm_mem_per_job: int = 4  # 4GB per job\n",
    "slurm_walltime: str = \"11:00:00\"  # 11 hours (adaptively shutdown if no more jobs)\n",
    "slurm_partition: str = \"scavenge\"\n",
    "\n",
    "local_maximum_jobs: int = 10\n",
    "\n",
    "min_shots: int = 10_000_000  # p_L between 6.7e-5 ~ 3.9e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e0d42-0172-4296-82e4-d2f3c38a2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516907d-674b-4a3c-98a8-6db5215c0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qec_lego_bench.hpc.monte_carlo import MonteCarloJob, LogicalErrorResult, MonteCarloJobExecutor\n",
    "from qec_lego_bench.hpc.submitter.min_shots_submitter import MinShotsSubmitter\n",
    "from qec_lego_bench.hpc.submitter.precision_submitter import PrecisionSubmitter\n",
    "from qec_lego_bench.hpc.plotter.job_progress_plotter import JobProgressPlotter\n",
    "from qec_lego_bench.hpc.plotter.logical_error_rate_plotter import LogicalErrorRatePlotter\n",
    "from typing import Iterable\n",
    "from qec_lego_bench.cli.logical_error_rate import logical_error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30041c1e-13b7-4eea-8004-0eb14acf686d",
   "metadata": {},
   "source": [
    "### Define the job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8142cc-1ae8-4cab-87b4-150f3d59eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_node_limit\n",
    "label_vec = list(range(50))\n",
    "\n",
    "jobs = [MonteCarloJob(label=label) for label in label_vec]\n",
    "\n",
    "\n",
    "def monte_carlo_function(shots: int, label: int = 1) -> tuple[int, LogicalErrorResult]:\n",
    "    stats = logical_error_rate(decoder=decoder, code=code, noise=noise, max_shots=shots, max_errors=shots, no_progress=True, no_print=True)\n",
    "    return stats.shots, LogicalErrorResult(errors=stats.errors, discards=stats.discards)\n",
    "\n",
    "monte_carlo_function(1000, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d93cd-d9b3-4d1e-8b5d-0c74daba2532",
   "metadata": {},
   "source": [
    "### Define the strategy to submit jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a795050-5167-453b-935b-1988d12cbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_shots_submitter = MinShotsSubmitter(shots=min_shots)\n",
    "precision_submitter = PrecisionSubmitter(time_limit=100*3600, min_precision=0.3, target_precision=0.01)\n",
    "precision_submitter_2 = PrecisionSubmitter(time_limit=100*3600, min_precision=0.02, target_precision=0.003)\n",
    "def submitter(jobs: Iterable[MonteCarloJob]) -> list[tuple[MonteCarloJob, int]]:\n",
    "    submit = min_shots_submitter(jobs)\n",
    "    submit += precision_submitter(jobs)\n",
    "    submit += precision_submitter_2(jobs)\n",
    "    return submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4924ea-30ba-453e-be4e-2655da620ab4",
   "metadata": {},
   "source": [
    "### Define the callback, e.g. plotting the intermediate result and the list of remaining tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80825f-740f-46ad-a9cf-9e4c6916428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qec_lego_bench.hpc.monte_carlo import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from dataclasses import field\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ConsistencyPlotter:\n",
    "    label_vec: list[int]\n",
    "\n",
    "    hdisplay: display.DisplayHandle = field(\n",
    "        default_factory=lambda: display.display(\"\", display_id=True)\n",
    "    )\n",
    "\n",
    "    def __call__(self, executor: MonteCarloJobExecutor):\n",
    "        x_vec = []\n",
    "        y_vec = []\n",
    "        err_vec = []\n",
    "        for label in self.label_vec:\n",
    "            job = executor.get_job(label=label)\n",
    "            if job is None or job.result is None:\n",
    "                continue\n",
    "            x_vec.append(label)\n",
    "            stats = job.result.stats_of(job)  # type: ignore\n",
    "            y_vec.append(stats.failure_rate_value)\n",
    "            err_vec.append(stats.failure_rate_uncertainty)\n",
    "        if len(x_vec) == 0:\n",
    "            return\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.clear()\n",
    "        ax.errorbar(x_vec, y_vec, err_vec, label=f\"noise={noise}\")\n",
    "        ax.set_xlabel(\"label\")\n",
    "        ax.set_ylabel(\"logical error rate $p_L$\")\n",
    "        ax.set_xlim(min(self.label_vec) - 1, max(self.label_vec) + 1)\n",
    "        ax.set_ylim(5e-5, 5e-4)\n",
    "        ax.set_yscale(\"log\")\n",
    "        fig.legend()\n",
    "        self.hdisplay.update(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18764d-c419-42d1-8e30-7ff563680acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = ConsistencyPlotter(label_vec)\n",
    "progress_plotter = JobProgressPlotter()\n",
    "def callback(executor: MonteCarloJobExecutor):\n",
    "    plotter(executor)\n",
    "    progress_plotter(executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945d3ca-dd1c-4306-b1be-166f03c184cd",
   "metadata": {},
   "source": [
    "## The rest of the notebook runs the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387ce78-3366-43e0-bcb0-f7f0372a5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dask_jobqueue import SLURMCluster\n",
    "    from dask.distributed import Client\n",
    "    n_workers = slurm_maximum_jobs // slurm_cores_per_node\n",
    "    assert n_workers <= 200, \"Yale HPC forbids submitting more than 200 jobs per hour\"\n",
    "    slurm_job_folder = os.path.join(os.path.abspath(os.getcwd()), \"slurm_job\")\n",
    "    cluster = SLURMCluster(\n",
    "        queue=slurm_partition,\n",
    "        cores=slurm_cores_per_node,\n",
    "        processes=slurm_cores_per_node,\n",
    "        memory=f\"{slurm_mem_per_job * slurm_cores_per_node} GB\",\n",
    "        walltime=slurm_walltime,\n",
    "        job_extra_directives=[f'--out=\"{slurm_job_folder}/%j.out\"', f'--error=\"{slurm_job_folder}/%j.err\"'],\n",
    "    )\n",
    "    print(cluster.job_script())\n",
    "    # cluster.scale(slurm_maximum_jobs)\n",
    "    cluster.adapt(minimum=slurm_maximum_jobs, maximum=slurm_maximum_jobs)  # allow respawn\n",
    "    shudown_cluster = True\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    cluster = LocalCluster(n_workers=local_maximum_jobs)\n",
    "    shudown_cluster = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2f4f7-5140-4278-9370-208babb9b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster.dashboard_link)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5771e-be93-48cd-bebf-0a890a143bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shudown_cluster:\n",
    "    print(\"will shut down the cluster after job finishes; if this is not desired, set `shudown_cluster` to False\")\n",
    "with Client(cluster) as client:\n",
    "    try:\n",
    "        executor = MonteCarloJobExecutor(\n",
    "            client,\n",
    "            monte_carlo_function,\n",
    "            jobs,\n",
    "            filename=json_filename,\n",
    "        )\n",
    "        executor.execute(submitter, loop_callback=callback)\n",
    "    finally:\n",
    "        if shudown_cluster:\n",
    "            print(\"shutting down the whole cluster; if this is not desired, set `shudown_cluster` to False\")\n",
    "            client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d408e1-ab6e-4965-87db-3772613e0696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb7ce6-438e-4f07-b3e4-dd8bea8f2362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
