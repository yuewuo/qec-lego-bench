{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d: float = 3\n",
    "p: float = 0.001\n",
    "code: str = f\"rsc(d={d},p={p})\"\n",
    "noise: str = \"none\"\n",
    "\n",
    "slurm_maximum_jobs = 300\n",
    "slurm_cores_per_node: int = 10  # (slurm_maximum_jobs // slurm_cores_per_node) should not exceed 200\n",
    "slurm_mem_per_job: int = 4  # 4GB per job because we have very large instances\n",
    "slurm_extra = dict(\n",
    "    walltime = \"1-00:00:00\",  # adaptively shutdown if no more jobs\n",
    "    queue = \"scavenge\",  # use with caution: dask does not seem to handle scavenge workers well\n",
    "    job_extra_directives = [\"--requeue\"],  # use with scavenge partition will help spawn scavenged jobs\n",
    ")\n",
    "\n",
    "json_filename: str | None = None\n",
    "force_finished: bool = False  # only plot the figure and do not run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_vec: list[float] = [0.2 * e for e in range(5)] + [0.9, 0.95, 0.98, 1]  # erasure conversion rate\n",
    "c_vec = [0, 50, 1000]\n",
    "max_iter_vec = [0, 5]\n",
    "osd_order_vec = [0, 10]\n",
    "\n",
    "mwpf_decoder_vec = [f\"mwpf(c={c})\" for c in c_vec] + [f\"mwpf(c={c},pass_circuit=1)\" for c in c_vec]\n",
    "bposd0_decoder_vec = [f\"bposd(max_iter={max_iter})\" for max_iter in max_iter_vec]\n",
    "bposdn_decoder_vec = [f\"bposd(max_iter={max_iter},osd_order={osd_order},osd_method=osd_e)\" for max_iter in max_iter_vec for osd_order in osd_order_vec]\n",
    "bpuf_decoder_vec = [f\"bpuf(max_iter={max_iter})\" for max_iter in max_iter_vec]\n",
    "\n",
    "decoder_vec = mwpf_decoder_vec + bposd0_decoder_vec + bposdn_decoder_vec + bpuf_decoder_vec + [\"mwpm\"]\n",
    "print(\"number of decoders:\", len(decoder_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "from dotmap import DotMap as dmap\n",
    "\n",
    "if json_filename is None:\n",
    "    json_filename = \"zdat-\" + slugify(code) + \".json\"\n",
    "print(json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qec_lego_bench.hpc.monte_carlo import *\n",
    "from qec_lego_bench.hpc.submitter import *\n",
    "from qec_lego_bench.hpc.plotter import *\n",
    "from typing import Iterable\n",
    "from qec_lego_bench.cli.logical_error_rate import logical_error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [MonteCarloJob(decoder, ecr, no_detectors) for decoder in decoder_vec for ecr in ecr_vec for no_detectors in [True, False]]\n",
    "\n",
    "def monte_carlo_function(shots: int, decoder: str, ecr: float, no_detectors: bool) -> tuple[int, LogicalErrorResult]:\n",
    "    stats = logical_error_rate(\n",
    "        decoder=decoder,\n",
    "        code=code,\n",
    "        noise=noise,\n",
    "        noise2=f\"erasure_conversion(rate={ecr}\" + (\",no_detectors=1)\" if no_detectors else \")\"),\n",
    "        max_shots=shots,\n",
    "        max_errors=shots,\n",
    "        no_progress=True,\n",
    "        no_print=True,\n",
    "    )\n",
    "    return stats.shots, LogicalErrorResult(errors=stats.errors, discards=stats.discards)\n",
    "\n",
    "\n",
    "print(monte_carlo_function(1000, decoder_vec[0], 0.5, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the strategy to submit jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_shot_submitter = MinShotsSubmitter(shots=1000)\n",
    "barrier = SubmitterBarrier()\n",
    "precision_submitter = PrecisionSubmitter(\n",
    "    time_limit=100 * 3600, min_precision=None, target_precision=0.03  # min_precision = None to force reach the target precision\n",
    ")\n",
    "\n",
    "def submitter(executor: MonteCarloJobExecutor) -> list[tuple[MonteCarloJob, int]]:\n",
    "    submit = min_shot_submitter(executor)\n",
    "    if barrier(executor, submit):  # previous submitter all finished\n",
    "        submit += precision_submitter(executor)\n",
    "    return submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest of the notebook runs the evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a cluster by intelligently choose Slurm or Local cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_connector():\n",
    "    try:\n",
    "        from dask_jobqueue import SLURMCluster\n",
    "        from dask.distributed import Client\n",
    "        n_workers = slurm_maximum_jobs // slurm_cores_per_node\n",
    "        assert n_workers <= 200, \"Yale HPC forbids submitting more than 200 jobs per hour\"\n",
    "        slurm_job_folder = os.path.join(os.path.abspath(os.getcwd()), \"slurm_job\")\n",
    "        job_extra_directives=[f'--out=\"{slurm_job_folder}/%j.out\"', f'--error=\"{slurm_job_folder}/%j.err\"']\n",
    "        if 'job_extra_directives' in slurm_extra:\n",
    "            job_extra_directives += slurm_extra['job_extra_directives']\n",
    "            del slurm_extra['job_extra_directives']\n",
    "        cluster = SLURMCluster(\n",
    "            cores=slurm_cores_per_node,\n",
    "            processes=slurm_cores_per_node,\n",
    "            memory=f\"{slurm_mem_per_job * slurm_cores_per_node} GB\",\n",
    "            job_extra_directives=job_extra_directives,\n",
    "            **slurm_extra,\n",
    "        )\n",
    "        print(cluster.job_script())\n",
    "        # cluster.scale(slurm_maximum_jobs)\n",
    "        cluster.adapt(minimum=slurm_maximum_jobs, maximum=slurm_maximum_jobs)  # allow respawn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        from dask.distributed import Client, LocalCluster\n",
    "        cluster = LocalCluster(n_workers=local_maximum_jobs)\n",
    "    print(\"cluster dashboard link:\", cluster.dashboard_link)\n",
    "    client = Client(cluster)\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MonteCarloExecutorConfig()\n",
    "config.max_submitted_job = max(config.max_submitted_job, 3 * slurm_maximum_jobs)\n",
    "executor = MonteCarloJobExecutor(\n",
    "    monte_carlo_function,\n",
    "    jobs,\n",
    "    config=config,\n",
    "    filename=json_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the callback, e.g. plotting the intermediate result and the list of remaining tasks\n",
    "\n",
    "(I have to put them in the same block as the actual execution, otherwise it won't update in VScode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # add some sleep to let them work properly in VScode Jupyter notebook\n",
    "\n",
    "time.sleep(0.2)\n",
    "progress_plotter = JobProgressPlotter()\n",
    "time.sleep(0.2)\n",
    "memory_plotter = MemoryUsagePlotter()\n",
    "time.sleep(0.2)\n",
    "progress_plotter_by_name = JobProgressPlotter(sort_by_name=True)\n",
    "time.sleep(0.2)\n",
    "\n",
    "\n",
    "def callback(executor: MonteCarloJobExecutor):\n",
    "    progress_plotter(executor)\n",
    "    time.sleep(0.1)\n",
    "    progress_plotter_by_name(executor)\n",
    "    time.sleep(0.1)\n",
    "    memory_plotter(executor)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\n",
    "    \"will shut down the cluster after job finishes; if this is not desired, set `shutdown_cluster` to False\"\n",
    ")\n",
    "\n",
    "executor.execute(\n",
    "    client_connector=client_connector,\n",
    "    submitter=submitter,\n",
    "    loop_callback=callback,\n",
    "    shutdown_cluster=True,\n",
    "    force_finished=force_finished,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
